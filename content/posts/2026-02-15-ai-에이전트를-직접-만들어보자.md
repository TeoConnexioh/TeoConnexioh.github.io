---
title: "AI 에이전트를 직접 만들어보자"
date: 2026-02-15
tags: ["ai", "agent", "llm", "python", "에이전트", "프레임워크"]
summary: "에이전트 프레임워크를 쓸까, 직접 만들까? 에이전트의 핵심인 도구 호출 루프를 직접 구현해보고, 도구 설계부터 메모리까지 실전 팁을 정리했다."
draft: false
---

![AI 에이전트 직접 만들기](/images/build-ai-agent.png)

## 들어가며

[이전 글](/posts/2026-02-15-ai-에이전트란-무엇인가/)에서 AI 에이전트의 개념을 정리했다. LLM이라는 두뇌에 도구, 메모리, 계획 능력을 붙여서 자율적으로 행동하는 시스템이라고 했다.

개념은 알겠는데, 그래서 어떻게 만드는 건데?

이번 글에서는 실제로 에이전트를 구축하는 방법을 다룬다. 프레임워크를 쓸 수도 있고 직접 짤 수도 있는데, 둘 다 해본 입장에서 솔직하게 비교해보겠다.

## 에이전트 프레임워크 선택지

2026년 현재, 에이전트를 만들 수 있는 프레임워크가 꽤 많다. 주요한 것들을 정리하면:

| 프레임워크 | 특징 | 적합한 경우 |
|---|---|---|
| **LangChain / LangGraph** | 가장 큰 생태계, 풍부한 통합 | 다양한 LLM/도구를 조합할 때 |
| **CrewAI** | 멀티 에이전트 협업에 특화 | 역할 분담이 필요한 복잡한 워크플로우 |
| **OpenAI Agents SDK** | OpenAI 모델과 긴밀한 통합 | OpenAI API 중심으로 빠르게 만들 때 |
| **직접 구현** | 완전한 제어, 의존성 최소 | 구조를 이해하고 싶거나 경량화가 필요할 때 |

### 프레임워크 vs 직접 구현, 뭘 써야 할까?

솔직히 말하면, **처음에는 직접 구현해보는 걸 추천한다.** 이유는 단순하다:

1. 에이전트의 핵심 루프가 생각보다 단순해서, 프레임워크 없이도 충분히 만들 수 있다
2. 프레임워크의 추상화 뒤에서 뭐가 일어나는지 이해해야 디버깅할 수 있다
3. 프레임워크 API가 자주 바뀌어서 학습 비용이 높다

물론 프로덕션에서 여러 에이전트를 조합하거나, 다양한 LLM 프로바이더를 지원해야 한다면 프레임워크가 편하다. 하지만 "에이전트가 뭔지 이해하고 싶다"면 직접 만들어보는 게 100배 낫다.

## 에이전트를 직접 만들어보자

에이전트의 핵심은 결국 하나의 루프다:

{{< mermaid >}}
flowchart TD
    A[사용자 메시지 수신] --> B[LLM 호출<br/>도구 목록 + 대화 히스토리 전달]
    B --> C{LLM 응답 확인}
    C -->|도구 호출 요청| D[도구 실행]
    D --> E[실행 결과를 히스토리에 추가]
    E --> B
    C -->|최종 텍스트 응답| F[사용자에게 응답 반환]
{{< /mermaid >}}

이걸 Python으로 구현하면 이렇다:

```python
import openai
import json

client = openai.OpenAI(api_key="YOUR_API_KEY")

# 1. 도구 정의
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "특정 도시의 현재 날씨를 조회합니다",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "도시 이름 (예: Seoul, Tokyo)"
                    }
                },
                "required": ["city"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "웹에서 정보를 검색합니다",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "검색어"
                    }
                },
                "required": ["query"]
            }
        }
    }
]

# 2. 도구 실행 함수
def execute_tool(name: str, arguments: dict) -> str:
    if name == "get_weather":
        # 실제로는 날씨 API를 호출
        return json.dumps({"city": arguments["city"], "temp": -2, "condition": "맑음"})
    elif name == "search_web":
        # 실제로는 검색 API를 호출
        return json.dumps({"results": [{"title": "검색 결과", "snippet": "..."}]})
    else:
        return json.dumps({"error": f"Unknown tool: {name}"})

# 3. 에이전트 루프 — 이게 전부다
def run_agent(user_message: str):
    messages = [
        {"role": "system", "content": "당신은 도움이 되는 AI 어시스턴트입니다. 필요한 경우 도구를 사용하세요."},
        {"role": "user", "content": user_message}
    ]

    while True:
        # LLM 호출
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            tools=tools
        )

        choice = response.choices[0]

        # 도구 호출이 없으면 → 최종 응답
        if choice.finish_reason == "stop":
            return choice.message.content

        # 도구 호출 처리
        if choice.message.tool_calls:
            messages.append(choice.message)  # assistant 메시지 추가

            for tool_call in choice.message.tool_calls:
                result = execute_tool(
                    tool_call.function.name,
                    json.loads(tool_call.function.arguments)
                )
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": result
                })
            # 루프 계속 → 다시 LLM 호출

# 실행
print(run_agent("서울 날씨 어때?"))
```

**60줄도 안 되는 코드다.** 이게 에이전트의 본질이다. 나머지는 전부 이 루프 위에 쌓는 것들이다.

## 아키텍처 전체 그림

실제로 쓸 만한 에이전트를 만들려면 몇 가지를 더 붙여야 한다:

{{< mermaid >}}
graph TB
    User[👤 사용자] --> Agent[🤖 에이전트 코어]
    
    subgraph Core[에이전트 코어]
        Loop[에이전트 루프]
        Prompt[시스템 프롬프트]
        Loop --- Prompt
    end
    
    Agent --> LLM[🧠 LLM API]
    
    subgraph Tools[도구들]
        T1[🔍 웹 검색]
        T2[📁 파일 R/W]
        T3[💻 코드 실행]
        T4[🗄️ DB 쿼리]
    end
    
    Agent --> Tools
    
    subgraph Memory[메모리]
        Short[단기: 대화 히스토리]
        Long[장기: 벡터DB / 파일]
    end
    
    Agent --> Memory
{{< /mermaid >}}

하나씩 살펴보자.

## 도구(Tool) 설계

도구 설계가 에이전트 성능의 절반을 결정한다고 해도 과언이 아니다. LLM이 도구를 정확하게 선택하고 올바른 파라미터를 넘기려면, **도구 설명이 명확해야** 한다.

### 좋은 도구 설계의 원칙

**1. 이름은 직관적으로**

```python
# ❌ 나쁜 예
"name": "proc_data"

# ✅ 좋은 예
"name": "search_products_by_category"
```

**2. 설명은 "언제 쓰는지"를 포함**

```python
# ❌ 나쁜 예
"description": "데이터를 가져옵니다"

# ✅ 좋은 예
"description": "카테고리별 상품 목록을 검색합니다. 사용자가 특정 카테고리의 상품을 찾거나 비교하고 싶을 때 사용하세요."
```

**3. 파라미터에 예시를 넣어라**

```python
"city": {
    "type": "string",
    "description": "도시 이름 (예: 'Seoul', 'New York', 'Tokyo')"
}
```

**4. 하나의 도구는 하나의 일만**

"검색하고 결과를 파일에 저장하는" 도구보다는, "검색하는" 도구와 "파일에 저장하는" 도구를 따로 만들어라. LLM이 조합하게 두는 게 낫다.

### 도구가 너무 많으면?

도구가 20개를 넘어가면 LLM이 헷갈리기 시작한다. 이럴 때는 두 가지 전략이 있다:

1. **카테고리별 그룹핑**: 관련 도구를 묶어서, 필요한 카테고리만 활성화
2. **2단계 선택**: 먼저 "어떤 종류의 도구가 필요한가"를 판단하고, 해당 카테고리의 도구만 노출

## 프롬프트 엔지니어링

에이전트에서 시스템 프롬프트는 매우 중요하다. LLM의 행동 패턴을 결정짓기 때문이다.

### 시스템 프롬프트 템플릿

```text
당신은 [역할]입니다.

## 행동 원칙
- 사용자의 요청을 정확히 이해한 후 행동하세요
- 불확실할 때는 도구를 사용하기 전에 사용자에게 확인하세요
- 한 번에 하나의 작업에 집중하세요

## 사용 가능한 도구
도구가 자동으로 제공됩니다. 각 도구의 설명을 읽고 적절할 때만 사용하세요.

## 응답 형식
- 한국어로 응답하세요
- 도구 실행 결과는 사용자가 이해하기 쉽게 정리해서 전달하세요
- 에러가 발생하면 원인과 대안을 함께 알려주세요
```

### 프롬프트 팁

**구체적인 제약을 줘라.** "적절히 판단하세요"보다 "3번 이상 도구 호출이 실패하면 사용자에게 알려주세요"가 낫다.

**출력 형식을 명시해라.** "JSON으로 응답하세요"가 아니라, 예시를 직접 보여줘라.

**네거티브 프롬프트도 효과적이다.** "하지 마세요" 류의 지시도 잘 먹힌다. "사용자가 요청하지 않은 추가 작업을 임의로 수행하지 마세요" 같은 식으로.

## 메모리 구현

### 단기 메모리: 대화 히스토리

가장 단순한 메모리는 `messages` 리스트 자체다. 대화가 쌓이면 LLM에 전달되는 컨텍스트가 길어진다.

문제는 토큰 한도다. 대화가 길어지면 결국 잘라내야 한다:

```python
def manage_context(messages: list, max_tokens: int = 100000) -> list:
    """컨텍스트 윈도우를 관리한다"""
    # 시스템 프롬프트는 항상 유지
    system = [m for m in messages if m["role"] == "system"]
    others = [m for m in messages if m["role"] != "system"]

    # 토큰 수 추정 (대략 한 글자 = 1~2 토큰)
    total = sum(len(str(m.get("content", ""))) for m in others)

    # 한도 초과시 오래된 메시지부터 제거
    while total > max_tokens and len(others) > 2:
        removed = others.pop(0)
        total -= len(str(removed.get("content", "")))

    return system + others
```

### 장기 메모리: 세션을 넘어서

대화가 끝나도 기억을 유지하고 싶다면, 외부 저장소가 필요하다.

**방법 1: 파일 기반 (단순하지만 효과적)**

```python
import json
from datetime import datetime

def save_memory(key: str, content: str):
    """중요한 정보를 파일에 저장"""
    memories = {}
    try:
        with open("memories.json", "r") as f:
            memories = json.load(f)
    except FileNotFoundError:
        pass

    memories[key] = {
        "content": content,
        "timestamp": datetime.now().isoformat()
    }

    with open("memories.json", "w") as f:
        json.dump(memories, f, ensure_ascii=False, indent=2)

def recall_memory(key: str) -> str | None:
    """저장된 정보를 불러온다"""
    try:
        with open("memories.json", "r") as f:
            memories = json.load(f)
        return memories.get(key, {}).get("content")
    except FileNotFoundError:
        return None
```

**방법 2: 벡터DB 기반 (의미 검색이 필요할 때)**

텍스트를 임베딩 벡터로 변환해서 저장하고, 유사한 내용을 검색한다. ChromaDB, Pinecone, Weaviate 같은 벡터DB를 쓴다.

```python
import chromadb

chroma = chromadb.Client()
collection = chroma.create_collection("agent_memory")

# 저장
collection.add(
    documents=["사용자는 Python을 선호한다", "프로젝트 마감은 3월 15일이다"],
    ids=["pref_1", "deadline_1"]
)

# 검색 — "이 사용자가 좋아하는 언어는?"
results = collection.query(
    query_texts=["프로그래밍 언어 선호도"],
    n_results=1
)
# → "사용자는 Python을 선호한다"가 반환됨
```

파일 기반은 구현이 간단하고, 벡터DB는 "기억이 많아졌을 때"의 검색 성능이 좋다. 처음에는 파일 기반으로 시작하고, 필요할 때 벡터DB로 전환하는 게 현실적이다.

## 실전 팁과 주의점

에이전트를 만들고 운영하면서 배운 것들을 정리한다.

### 1. 무한 루프 방지

에이전트가 같은 도구를 반복 호출하거나, 목표를 달성하지 못하고 계속 시도하는 경우가 있다. **최대 반복 횟수를 반드시 설정하라.**

```python
MAX_ITERATIONS = 10

for i in range(MAX_ITERATIONS):
    response = call_llm(messages)
    if response.finish_reason == "stop":
        break
    # ... 도구 실행
else:
    return "최대 시도 횟수를 초과했습니다. 요청을 다시 확인해주세요."
```

### 2. 에러 핸들링은 LLM에게 맡겨라

도구 실행이 실패했을 때, 에러를 삼키지 말고 LLM에게 그대로 돌려줘라. LLM은 에러 메시지를 보고 다른 방법을 시도하거나, 사용자에게 상황을 설명할 수 있다.

```python
try:
    result = execute_tool(name, args)
except Exception as e:
    result = json.dumps({"error": str(e), "suggestion": "다른 파라미터로 시도해보세요"})
```

### 3. 비용 관리

에이전트는 LLM을 여러 번 호출한다. 복잡한 작업이면 10번 이상도 쉽게 간다. 비용을 추적하고 한도를 설정하라.

```python
total_tokens = 0

for iteration in range(MAX_ITERATIONS):
    response = call_llm(messages)
    total_tokens += response.usage.total_tokens

    if total_tokens > TOKEN_BUDGET:
        return "토큰 예산을 초과했습니다."
```

### 4. 로깅은 생명이다

에이전트가 어떤 도구를 왜 선택했는지, 입력과 출력은 뭐였는지 전부 로그로 남겨라. 문제가 생겼을 때 유일한 디버깅 수단이다.

### 5. 사람의 승인(Human-in-the-loop)

위험한 도구(파일 삭제, 외부 API 호출, 결제 등)를 실행하기 전에 사용자 확인을 받는 구조를 넣어라. 에이전트가 자율적이라고 해서 모든 걸 맡기면 안 된다.

## 정리

에이전트의 핵심은 **루프**다. LLM을 호출하고, 도구가 필요하면 실행하고, 결과를 다시 LLM에 넘기고, 목표가 달성될 때까지 반복한다. 이 루프는 60줄이면 구현할 수 있다.

그 위에 좋은 도구 설계, 적절한 프롬프트, 메모리 시스템을 얹으면 쓸 만한 에이전트가 된다.

프레임워크는 편하지만 마법이 아니다. 핵심 원리를 이해하고 있으면 어떤 프레임워크를 쓰든, 혹은 직접 만들든 좋은 에이전트를 만들 수 있다.

다음 글에서는 에이전트의 안전성과 평가 — 에이전트가 제대로 동작하는지 어떻게 테스트하고, 프로덕션에서 안전하게 운영하는지 — 를 다뤄볼 예정이다.
