---
title: "AI 에이전트란 무엇인가"
date: 2026-02-15
tags: ["ai", "agent", "llm", "에이전트"]
summary: "챗봇과 AI 에이전트는 뭐가 다를까? 에이전트의 핵심 구성요소와 실제 활용 사례, 그리고 현재 한계까지 정리했다."
draft: false
---

## 들어가며

ChatGPT가 나온 지 2년이 넘었다. 이제 LLM을 API로 호출하는 건 누구나 할 수 있다. 그런데 요즘 기술 커뮤니티에서는 "에이전트(Agent)"라는 단어가 훨씬 자주 들린다. 단순히 질문에 답하는 챗봇과 AI 에이전트는 뭐가 다른 걸까?

이 글에서는 AI 에이전트의 개념을 정리하고, 실제로 어디에 쓰이는지, 그리고 아직 어디가 부족한지 솔직하게 다뤄보려 한다.

## 챗봇과 에이전트의 차이

일반적인 챗봇은 이런 구조다:

```
사용자 입력 → LLM 호출 → 응답 반환
```

한 번 물어보면 한 번 답한다. 대화 기록을 붙여서 맥락을 유지할 수는 있지만, 본질적으로 **"질문-응답" 한 턴**이다. 외부 세계에 영향을 주지 못한다.

에이전트는 다르다:

```
목표 설정 → 계획 수립 → 도구 사용 → 결과 확인 → 필요하면 재시도 → 완료
```

핵심 차이는 **자율성(autonomy)**이다. 에이전트는 목표를 받으면 스스로 어떤 단계를 거쳐야 하는지 판단하고, 도구를 사용해서 실제 행동을 하고, 결과를 보고 다음 행동을 결정한다.

간단한 예를 들어보자:

- **챗봇**: "서울 날씨 알려줘" → "서울은 현재 맑고 기온은 5도입니다" (미리 학습된 지식 기반, 실시간 아님)
- **에이전트**: "서울 날씨 알려줘" → 날씨 API 호출 → 실제 데이터 가져옴 → "현재 서울은 맑고 기온은 -2도입니다"

사소해 보이지만, "도구를 써서 실제 세계의 정보를 가져온다"는 점이 결정적이다.

## 에이전트의 핵심 구성요소

AI 에이전트를 구성하는 요소는 크게 네 가지다.

### 1. LLM — 두뇌

에이전트의 중심에는 LLM이 있다. 사용자의 요청을 이해하고, 어떤 도구를 써야 할지 판단하고, 결과를 해석하는 역할을 한다. GPT-4, Claude, Gemini 같은 모델이 여기에 해당한다.

중요한 건 LLM 자체가 에이전트는 아니라는 점이다. LLM은 "생각하는" 부분이고, 나머지 구성요소가 합쳐져야 에이전트가 된다.

### 2. 도구(Tools) — 손과 발

에이전트가 실제로 뭔가를 할 수 있게 해주는 수단이다. 예를 들면:

- 웹 검색
- 파일 읽기/쓰기
- 코드 실행
- API 호출
- 데이터베이스 쿼리
- 브라우저 조작

LLM이 "이 상황에서는 검색이 필요하겠다"고 판단하면, 검색 도구를 호출하고 결과를 다시 LLM에 넘긴다. 이 과정이 자동으로 일어난다.

```python
# 에이전트 도구 정의 예시 (의사 코드)
tools = [
    {
        "name": "web_search",
        "description": "웹에서 정보를 검색합니다",
        "parameters": {
            "query": {"type": "string", "description": "검색어"}
        }
    },
    {
        "name": "run_code",
        "description": "Python 코드를 실행합니다",
        "parameters": {
            "code": {"type": "string", "description": "실행할 코드"}
        }
    }
]
```

### 3. 메모리(Memory) — 경험의 축적

단기 메모리와 장기 메모리로 나뉜다.

- **단기 메모리**: 현재 대화의 맥락. 이전 턴에서 뭘 했는지, 어떤 도구를 썼는지 기억한다.
- **장기 메모리**: 이전 세션의 정보를 저장해두고 나중에 참조한다. 파일에 기록하거나 벡터 DB에 저장하는 방식이 일반적이다.

메모리가 없으면 에이전트는 매번 처음부터 시작해야 한다. "어제 분석했던 데이터를 이어서 처리해줘"라는 요청을 처리할 수 없다.

### 4. 계획(Planning) — 전략적 사고

복잡한 작업을 받으면 에이전트는 이를 하위 작업으로 분해한다.

예를 들어 "이 CSV 데이터를 분석해서 보고서를 만들어줘"라는 요청을 받으면:

1. CSV 파일을 읽는다
2. 데이터 구조를 파악한다
3. 기초 통계를 계산한다
4. 주요 인사이트를 도출한다
5. 보고서 형태로 정리한다

각 단계의 결과를 보고 다음 단계를 조정하기도 한다. 3단계에서 이상치가 발견되면 추가 분석 단계를 끼워넣는 식이다.

## 실행 루프: 에이전트가 일하는 방식

이 네 가지 요소가 합쳐져서 하나의 **실행 루프(Agentic Loop)**를 형성한다:

```
┌─────────────────────────────────────┐
│  1. 사용자 목표 수신                   │
│  2. 계획 수립 (하위 작업 분해)          │
│  3. 다음 행동 결정 (LLM 추론)          │
│  4. 도구 실행                         │
│  5. 결과 관찰 & 메모리 업데이트         │
│  6. 목표 달성? → 완료 / 아니면 → 3으로  │
└─────────────────────────────────────┘
```

이 루프가 핵심이다. 한 번 LLM을 호출하고 끝나는 게 아니라, **목표를 달성할 때까지 반복**한다.

## 실제 활용 사례

### 코딩 에이전트

코드를 작성하고, 실행하고, 에러가 나면 수정하고, 테스트까지 돌리는 에이전트. GitHub Copilot이 자동완성 수준이라면, Cursor나 Claude Code 같은 도구는 파일을 직접 만들고 수정하고 터미널 명령어를 실행하는 수준까지 왔다.

"이 프로젝트에 로그인 기능을 추가해줘"라고 하면, 관련 파일을 읽고 → 코드를 작성하고 → 테스트를 실행하고 → 에러를 수정하는 과정을 자율적으로 반복한다.

### 데이터 분석 에이전트

데이터를 주면 알아서 탐색하고, 시각화하고, 인사이트를 정리하는 에이전트. 예를 들어 매출 데이터를 던져주면 "전월 대비 15% 성장했고, 특히 A 카테고리의 기여가 컸다"는 식의 분석을 자동으로 만들어낸다.

### 자동화 에이전트

반복적인 업무를 처리하는 에이전트. 이메일을 읽고 분류하거나, 일정을 조율하거나, 모니터링 알림을 받아 초기 대응을 하는 식이다. 기존 RPA(Robotic Process Automation)와 비슷하지만, 규칙을 하드코딩하는 대신 LLM이 상황에 맞게 판단한다는 점이 다르다.

## 현재 한계

솔직히 말하면, 아직 부족한 게 많다.

**환각(Hallucination)**: LLM이 사실이 아닌 내용을 자신 있게 말하는 문제는 에이전트에서 더 위험하다. 챗봇이 틀린 답을 하면 사람이 걸러내지만, 에이전트가 잘못된 판단으로 도구를 실행하면 실제 피해가 발생할 수 있다.

**비용과 속도**: 에이전트는 하나의 작업에 LLM을 여러 번 호출한다. 복잡한 작업이면 수십 번 호출하기도 한다. 비용과 지연 시간이 누적된다.

**디버깅의 어려움**: 에이전트가 왜 그런 결정을 내렸는지 추적하기 어렵다. 10단계를 거쳐 나온 결과가 이상할 때, 어디서 잘못됐는지 찾는 건 꽤 고된 일이다.

**안전성**: 에이전트에게 파일 삭제, 코드 실행, 외부 API 호출 같은 권한을 줄 때, 의도치 않은 동작을 어떻게 방지할지는 여전히 풀어야 할 과제다.

## 마무리

AI 에이전트는 "똑똑한 챗봇"이 아니라 **"목표를 향해 스스로 행동하는 시스템"**이다. LLM이라는 두뇌에 도구, 메모리, 계획 능력을 붙여서, 단순 질문-응답을 넘어 실제 작업을 수행할 수 있게 만든 것이다.

아직 완벽하지 않고 한계도 명확하다. 하지만 코딩, 데이터 분석, 업무 자동화 영역에서 이미 실용적으로 쓰이고 있고, 발전 속도도 빠르다.

다음 글에서는 실제로 에이전트를 구축하는 방법 — 프레임워크 선택부터 도구 설계, 프롬프트 엔지니어링까지 — 을 다뤄볼 예정이다.
